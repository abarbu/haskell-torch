{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "{-# LANGUAGE AllowAmbiguousTypes, ConstraintKinds, ExtendedDefaultRules, FlexibleContexts, FlexibleInstances, GADTs, OverloadedStrings, MultiParamTypeClasses #-}\n",
    "{-# LANGUAGE PolyKinds, QuasiQuotes, RankNTypes, ScopedTypeVariables, TemplateHaskell, TypeApplications, TypeFamilies                  #-}\n",
    "{-# LANGUAGE TypeFamilyDependencies, TypeInType, TypeOperators, UndecidableInstances, CPP                                                   #-}\n",
    "{-# OPTIONS -fplugin GHC.TypeLits.Normalise -fplugin GHC.TypeLits.KnownNat.Solver -fplugin Plugin.DefaultType #-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-thousand",
   "metadata": {},
   "source": [
    "| This example shows you Haskell & PyTorch code right next to one\n",
    "another. You get an idea of how the two are related and how to do so some of\n",
    "he most basic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "import           Control.Monad\n",
    "import           Data.Default\n",
    "import           Data.Kind\n",
    "import           Data.Maybe\n",
    "import           Data.Singletons\n",
    "import           Data.String.InterpolateIO\n",
    "import qualified Data.Vector                 as V'\n",
    "import           Data.Vector.Storable        (Vector)\n",
    "import qualified Data.Vector.Storable        as V\n",
    "import           Foreign.C.Types\n",
    "import           Pipes\n",
    "import qualified Pipes.Prelude               as P\n",
    "import           Torch\n",
    "import qualified Torch.C.Variable            as C\n",
    "import           Torch.Datasets.Vision.CIFAR\n",
    ":set -fplugin GHC.TypeLits.Normalise -fplugin GHC.TypeLits.KnownNat.Solver -fplugin Plugin.DefaultType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece8203-5c7b-41de-b1d0-0de881226153",
   "metadata": {},
   "outputs": [],
   "source": [
    ":set -fplugin Plugin.DefaultType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549b105-177a-427f-ac45-ead10f01a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- | Basic autograd\n",
    "ex1 = do\n",
    "  setSeed 0\n",
    "  -- You can specify the device if you want to like so:\n",
    "  s <- typed @'TFloat <$> stored @KCpu <$> toScalar ((float 1) :: Float)\n",
    "  -- Or, you can rely on Plugin.DefaultType to guess what you might want\n",
    "  -- Without that plugin, you will get an ambiguous type error.\n",
    "  -- s <- toScalar (float 1)\n",
    "  -- Create tensors.\n",
    "  x <- needGrad . stored @KCpu =<< toScalar ((float 1) :: Float)\n",
    "  w <- needGrad . typed @'TFloat =<< toScalar ((float 2) :: Float)\n",
    "  b <- needGrad .typed @'TFloat =<< toScalar ((float 3) :: Float)\n",
    "  putStrLn =<< [c|X: #{x}\n",
    "   W: #{w}\n",
    "   B: #{b}|]\n",
    "  -- Compute primal\n",
    "  y <- pure w ..* pure x ..+ pure b\n",
    "  -- Compute gradient\n",
    "  backward1 y False False\n",
    "  putStrLn =<< [c|dX: #{gradient x} expected 2\n",
    "   dW: #{gradient w} expected 1\n",
    "   dB: #{gradient b} expected 1|]\n",
    "  debuggingPrintADGraph y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c91e6-5e76-4611-8250-e8b6f30aaa5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- | Basic autograd with SGD\n",
    "ex2 = do\n",
    "  unsafeEnableGrad\n",
    "  setSeed 0\n",
    "  -- Create tensors of shape (10, 3) and (10, 2).\n",
    "  -- You can specify the type and/or the device\n",
    "  --  x <- typed @TFloat <$> stored @KCpu <$> sized (size_ @'[10,3]) <$> randn\n",
    "  -- Or you can let Plugin.DefaultType guess these types for you\n",
    "  -- It will prefer TFloat when it can fit it in, if not TInt, and onwards from there.\n",
    "  x <- sized (size_ @'[10,3]) <$> randn\n",
    "  y <- sized (size_ @'[10,2]) <$> randn\n",
    "  -- Weights and biases for a linear layer.\n",
    "  w <- gradP\n",
    "  --\n",
    "  let model = linear (inFeatures_ @3) (outFeatures_ @2) w\n",
    "  pred <- model x\n",
    "  let criterion = mseLoss y def\n",
    "  loss <- criterion pred\n",
    "  --\n",
    "  backward1 loss False False\n",
    "  putStrLn =<< [c|weights & biases:\\n#{w}\n",
    "  Loss: #{loss}|]\n",
    "  -- 1 step of gradient descent\n",
    "  params <- toParameters w\n",
    "  step_ (sgd (def { sgdLearningRate = 0.01 }) params)\n",
    "  --\n",
    "  pred <- model x\n",
    "  loss <- criterion pred\n",
    "  putStrLn =<< [c|Loss after 1 SGD step #{loss}|]\n",
    "  pure ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e394e434-51c9-4f90-9c16-3ab6786e8392",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- | Loading data from a Storable Vector\n",
    "ex3 = do\n",
    "  let v = V.fromList [1,2,3,4]\n",
    "  -- The resulting tensor is always on the CPU, does not have gradients enabled\n",
    "  -- and is marked as a leaf. Its type depends on the type of the Vector.  Only\n",
    "  -- Vectors with Foreign.C types are allowed (so CDouble instead of Double,\n",
    "  -- etc.).\n",
    "  --\n",
    "  -- For the result to be useful you must somehow constrain the types.  Here we\n",
    "  -- do so locally using type application but if some downstream consumer of t\n",
    "  -- constrained its shape we would not need to do so.\n",
    "  --\n",
    "  -- This is one of the few interfaces between runtime values and types. It will\n",
    "  -- error out if the size of the vector is not exactly equal to size of the\n",
    "  -- tensor.\n",
    "  t <- fromVector @'TDouble @'[4] v\n",
    "  -- Alternatively we can use the functions found under the Constraints heading\n",
    "  -- in Torch.Tensor. These have no runtime component, they just allow you to\n",
    "  -- constrain the types of tensors easily.\n",
    "  t' <- typed @'TDouble <$> sized (size_ @'[4]) <$> fromVector v\n",
    "  -- Or we can say that the new tensor should inherit its properties, aside from\n",
    "  -- AD status like if gradients are required, from another tensor.\n",
    "  t'' <- like t <$> fromVector v\n",
    "  -- A few other ways to create vectors exist, see the \"Tensor creation\" section\n",
    "  -- in Tensor.Torch, for example we can make the vector of all 1s that's just\n",
    "  -- like t.\n",
    "  t''' <- like t <$> ones\n",
    "  -- We can also convert tenstors back into vectors.\n",
    "  v' <- toVector t\n",
    "  print \"@@writing\"\n",
    "  writeModelToFile t \"/tmp/woof\"\n",
    "  print \"@@writing.post\"\n",
    "  tl <- like t <$> readModelFromFile \"/tmp/woof\"\n",
    "  print \"@@read\"\n",
    "  out t\n",
    "  out tl\n",
    "  out =<< t .== tl\n",
    "  print v'\n",
    "  print $ v == v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3de28c-5134-4e51-92b5-7e7e694194a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- | Input datasets\n",
    "ex4 = do\n",
    "  -- Datasets get downloaded and then streamed using Pipes\n",
    "  (train,test) <- cifar10 \"datasets/image/\"\n",
    "  -- Unpack the training set\n",
    "  (Right trainStream) <- liftM (transformObjectStream rgbImageToTensor) <$> fetchDataset train\n",
    "  -- Data is loaded on demand, here we read the first data point\n",
    "  (Just d) <- P.head trainStream\n",
    "  image <- typed @TByte <$> dataObject d\n",
    "  label <- dataLabel d\n",
    "  print $ dataProperties d\n",
    "  print $ size image\n",
    "  out label\n",
    "  -- All datasets can define any custom metadata that they want. CIFAR gives you\n",
    "  -- a map between indices and text labels so you can interpret the classes.\n",
    "  metadata <- metadataDataset train\n",
    "  print metadata\n",
    "  -- Lets iterate one by one over the first 10 data points shuffling with a\n",
    "  -- horizon of 1000\n",
    "  forEachData\n",
    "    (\\d -> do\n",
    "        print \"One data point at a time\"\n",
    "        -- Training code goes here\n",
    "        putStrLn =<< [c|n: #{dataProperties d} lab: #{dataLabel d}|])\n",
    "    (shuffle 1000 trainStream >-> P.take 10)\n",
    "  -- Same if we batch by 64. True means give us a partial batch at the end if our\n",
    "  -- data isn't divisble by 64.\n",
    "  forEachData\n",
    "    (\\ds -> do\n",
    "        print \"Batches of 64\"\n",
    "        print $ V'.length ds\n",
    "        mapM_ (\\d ->\n",
    "                          -- Training code goes here\n",
    "                          putStrLn =<< [c|n: #{dataProperties d} lab: #{dataLabel d}|]) ds)\n",
    "     (batch 64 True (shuffle 1000 trainStream) >-> P.take 3)\n",
    "  pure ()\n",
    "\n",
    "-- ex5 does not exist. We don't need anything like custom loaders, you just\n",
    "-- create pipes. Look at how the datasets are constructed in Torch.Datasets\n",
    "\n",
    "-- ex6 does not exist. Have a look at Torch.Models.Vision.AlexNet how to load\n",
    "-- pretrained models.\n",
    "\n",
    "-- ex7 does not exist. TODO We do not yet have integrated checkpointing\n",
    "-- support. You can save and load a model but we cannot yet do this with\n",
    "-- optimizers and cannot do it all for you in one go.\n",
    "\n",
    "-- Viewing the trace of a computation\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "ex8 = do\n",
    "  unsafeEnableGrad\n",
    "  setSeed 0\n",
    "  -- Create tensors of shape (10, 3) and (10, 2).\n",
    "  x <- sized (size_ @'[7,5]) <$> randn\n",
    "  y <- sized (size_ @'[7,2]) <$> randn\n",
    "  -- Weights and biases for a fully connected layer\n",
    "  w <- noGradP\n",
    "  let model = linear (inFeatures_ @5) (outFeatures_ @2) w\n",
    "  let criterion = mseLoss y def\n",
    "  params <- toParameters w\n",
    "  (loss, trace) <- withTracing [AnyTensor x, AnyTensor y] $ do\n",
    "    pred <- model x\n",
    "    criterion pred\n",
    "  putStrLn =<< [c|weights & biases:\\n#{w}\n",
    "Loss: #{loss}|]\n",
    "  printTrace trace\n",
    "  printTraceONNX trace [AnyTensor x, AnyTensor y] False 11\n",
    "  trace' <- parseTrace trace\n",
    "  summarizeTrace trace'\n",
    "  showTraceGraph trace False\n",
    "  -- 1 step of gradient descent\n",
    "  p <- toParameters w\n",
    "  step_ (sgd (def { sgdLearningRate = 0.01 }) p)\n",
    "  --\n",
    "  pred <- model x\n",
    "  loss <- criterion pred\n",
    "  putStrLn =<< [c|Loss after 1 SGD step #{loss}|]\n",
    "  pure ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37356f52-7033-4d51-8df0-81e446f5f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    ":set -fplugin GHC.TypeLits.KnownNat.Solver -fplugin Plugin.DefaultType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6f5fdd-145f-414d-b545-c55956335687",
   "metadata": {},
   "outputs": [],
   "source": [
    ":help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cfcb5a-1f76-4f91-a908-5f15d9b33104",
   "metadata": {},
   "outputs": [],
   "source": [
    ":set -fplugin GHC.TypeLits.Normalise -fplugin GHC.TypeLits.KnownNat.Solver -fplugin Plugin.DefaultType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b5d62-0d00-4b2e-8cea-7bb98279d196",
   "metadata": {},
   "outputs": [],
   "source": [
    ":set -Wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ad7fc-0a1b-4321-9f5c-65fff2f814ca",
   "metadata": {},
   "outputs": [],
   "source": [
    ":info GHC.TypeLits.Normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c24ed6a-2723-4ec5-ae09-0eaa5bdee8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    ":set -fplugin Plugin.DefaultType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2aa676-f02c-494a-a1a6-dce991bdbe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Plugin.DefaultType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ea078f-01f9-4080-8afe-edfd57978523",
   "metadata": {},
   "outputs": [],
   "source": [
    "getEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae02cd90-4b53-4fce-b5ad-9449683c1ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "getExecutablePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd69de6-7b56-41a9-bc0b-f08c52573d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "getEnv \"GHC_PKGCONF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e56cd-f650-4cba-a95a-abbf882c0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qualified System.Info\n",
    "import Data.List\n",
    "import Distribution.InstalledPackageInfo\n",
    "import GHC.Paths\n",
    "import System.Directory\n",
    "import System.Environment\n",
    "import System.FilePath\n",
    "import System.IO.Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a76a50e7-fa95-4cdc-86e4-45fa3d8cfb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Styles used for the Hoogle display in the pager */\n",
       ".hoogle-doc {\n",
       "display: block;\n",
       "padding-bottom: 1.3em;\n",
       "padding-left: 0.4em;\n",
       "}\n",
       ".hoogle-code {\n",
       "display: block;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "}\n",
       ".hoogle-text {\n",
       "display: block;\n",
       "}\n",
       ".hoogle-name {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-head {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-sub {\n",
       "display: block;\n",
       "margin-left: 0.4em;\n",
       "}\n",
       ".hoogle-package {\n",
       "font-weight: bold;\n",
       "font-style: italic;\n",
       "}\n",
       ".hoogle-module {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-class {\n",
       "font-weight: bold;\n",
       "}\n",
       ".get-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "white-space: pre-wrap;\n",
       "}\n",
       ".show-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "margin-left: 1em;\n",
       "}\n",
       ".mono {\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "}\n",
       ".err-msg {\n",
       "color: red;\n",
       "font-style: italic;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "display: block;\n",
       "}\n",
       "#unshowable {\n",
       "color: red;\n",
       "font-weight: bold;\n",
       "}\n",
       ".err-msg.in.collapse {\n",
       "padding-top: 0.7em;\n",
       "}\n",
       ".highlight-code {\n",
       "white-space: pre;\n",
       "font-family: monospace;\n",
       "}\n",
       ".suggestion-warning { \n",
       "font-weight: bold;\n",
       "color: rgb(200, 130, 0);\n",
       "}\n",
       ".suggestion-error { \n",
       "font-weight: bold;\n",
       "color: red;\n",
       "}\n",
       ".suggestion-name {\n",
       "font-weight: bold;\n",
       "}\n",
       "</style><div class=\"suggestion-name\" style=\"clear:both;\">Unused LANGUAGE pragma</div><div class=\"suggestion-row\" style=\"float: left;\"><div class=\"suggestion-warning\">Found:</div><div class=\"highlight-code\" id=\"haskell\">{-# LANGUAGE PolyKinds, RankNTypes, ScopedTypeVariables, TypeApplications, TypeFamilies #-}</div></div><div class=\"suggestion-row\" style=\"float: left;\"><div class=\"suggestion-warning\">Why Not:</div><div class=\"highlight-code\" id=\"haskell\">{-# LANGUAGE RankNTypes, ScopedTypeVariables #-}</div></div><div class=\"suggestion-name\" style=\"clear:both;\">Unused LANGUAGE pragma</div><div class=\"suggestion-row\" style=\"float: left;\"><div class=\"suggestion-warning\">Found:</div><div class=\"highlight-code\" id=\"haskell\">{-# LANGUAGE TypeFamilyDependencies, TypeInType, TypeOperators, UndecidableInstances #-}</div></div><div class=\"suggestion-row\" style=\"float: left;\"><div class=\"suggestion-warning\">Why Not:</div><div class=\"highlight-code\" id=\"haskell\">{-# LANGUAGE TypeFamilyDependencies, TypeInType, UndecidableInstances #-}</div></div>"
      ],
      "text/plain": [
       "Line 2: Unused LANGUAGE pragma\n",
       "Found:\n",
       "{-# LANGUAGE PolyKinds, RankNTypes, ScopedTypeVariables, TypeApplications, TypeFamilies #-}\n",
       "Why not:\n",
       "{-# LANGUAGE RankNTypes, ScopedTypeVariables #-}Line 3: Unused LANGUAGE pragma\n",
       "Found:\n",
       "{-# LANGUAGE TypeFamilyDependencies, TypeInType, TypeOperators, UndecidableInstances #-}\n",
       "Why not:\n",
       "{-# LANGUAGE TypeFamilyDependencies, TypeInType, UndecidableInstances #-}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{-# LANGUAGE FlexibleContexts #-}\n",
    "{-# LANGUAGE PolyKinds, RankNTypes, ScopedTypeVariables, TypeApplications, TypeFamilies                  #-}\n",
    "{-# LANGUAGE TypeFamilyDependencies, TypeInType, TypeOperators, UndecidableInstances                                                   #-}\n",
    "import Data.Proxy\n",
    "import GHC.TypeLits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01fc228d-bf31-4756-858d-bf532e152866",
   "metadata": {},
   "outputs": [],
   "source": [
    "f :: forall n . (KnownNat n, KnownNat (n+2)) => Proxy n -> Integer\n",
    "f _ = natVal (Proxy :: Proxy n) + natVal (Proxy :: Proxy (n+2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71198e-d69f-4968-960c-658dff10d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f :: forall n . KnownNat n => Proxy n -> Integer\n",
    "f _ = natVal (Proxy :: Proxy n) + natVal (Proxy :: Proxy (n+2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe3842-bf7a-461f-b11e-12e1b2ab5964",
   "metadata": {},
   "outputs": [],
   "source": [
    ":set -fplugin GHC.TypeLits.KnownNat.Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04531601-921b-4837-ad57-fcc6b6cf9832",
   "metadata": {},
   "outputs": [],
   "source": [
    ":set -fplugin GHC.TypeLits.KnownNat.SolverX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8bf5a3-65c1-4a66-b6d9-1c1b3f27763f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Haskell - haskell",
   "language": "haskell",
   "name": "ihaskell_haskell"
  },
  "language_info": {
   "codemirror_mode": "Haskell",
   "file_extension": ".hs",
   "mimetype": "text/x-haskell",
   "name": "haskell",
   "pygments_lexer": "Haskell",
   "version": "8.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
